{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055e5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import Model, Preprocess\n",
    "\n",
    "from config import root, dir_resources\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9387d419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from ../Model\\v1\n"
     ]
    }
   ],
   "source": [
    "model_name = 'v1'\n",
    "model = Model.load_model( os.path.join(root, 'Model', model_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a2f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_name = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier( os.path.join(dir_resources, 'haarcascade', cascade_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bbeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_results(image_bgr, results):\n",
    "    result_shape = (512, 512)\n",
    "\n",
    "    extend_result_x = 300\n",
    "    start_x = 520\n",
    "    start_y = 20\n",
    "    pos_y_dif = 20\n",
    "    section_y_dif = 30\n",
    "\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.45\n",
    "    font_thickness = 1\n",
    "    \n",
    "    title_color = (255,255,255)\n",
    "    \n",
    "    name_add_x = 0\n",
    "    score_add_x = 100\n",
    "\n",
    "    line_add_x = 150\n",
    "    line_lenght = 100\n",
    "    line_thickness = 2\n",
    "    \n",
    "    from config import facial_expression_color_bgr as face_color\n",
    "    from config import facial_expression as face_name\n",
    "    \n",
    "    image = image_bgr.copy()\n",
    "    image = cv2.resize(image, result_shape)\n",
    "    \n",
    "    black_box = np.zeros((image.shape[0], extend_result_x, 3), dtype='uint8')\n",
    "    image = np.hstack((image, black_box))\n",
    "    \n",
    "    list_of_data = []\n",
    "    for result in results:\n",
    "        data = []\n",
    "        for i, score in enumerate(result):\n",
    "            datum = (score, face_name[i], face_color[i])\n",
    "            data.append(datum)\n",
    "        data.sort(reverse=True)\n",
    "        list_of_data.append(data)\n",
    "        \n",
    "    pos_x = start_x\n",
    "    pos_y = start_y\n",
    "    \n",
    "    for i, data in enumerate(list_of_data):\n",
    "        text_title = 'Index %d'%i\n",
    "        cv2.putText(image, text_title, (pos_x,pos_y), fontFace=font_face, fontScale=font_scale, color=title_color, thickness=font_thickness)\n",
    "        pos_y+=pos_y_dif\n",
    "        for score, name, color in data:\n",
    "            text_name = \"%-10s\"%name\n",
    "            cv2.putText(image, text_name, (pos_x + name_add_x,pos_y), fontFace=font_face, fontScale=font_scale, color=color, thickness=font_thickness)\n",
    "            \n",
    "            text_score = \"%4s%%\"%('%.1f'%(score*100))\n",
    "            cv2.putText(image, text_score, (pos_x + score_add_x,pos_y), fontFace=font_face, fontScale=font_scale, color=color, thickness=font_thickness)\n",
    "            \n",
    "            start_point = (int(pos_x + line_add_x), int(pos_y-5))\n",
    "            end_point = (int(start_point[0] + line_lenght * score), int(start_point[1]))\n",
    "            \n",
    "            cv2.line(image, start_point, end_point, color=color, thickness=line_thickness)\n",
    "            pos_y += pos_y_dif\n",
    "            \n",
    "        pos_y += section_y_dif\n",
    "    \n",
    "    return image\n",
    "\n",
    "def draw_bounding_boxes(image_bgr, bounding_boxes):\n",
    "    \n",
    "    color = (255,0,0)\n",
    "    \n",
    "    bounding_box_thickness = 2\n",
    "    \n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.45\n",
    "    font_thickness = 1\n",
    "    \n",
    "    title_add_x = 0\n",
    "    title_add_y = -10\n",
    "    \n",
    "    image = image_bgr.copy()\n",
    "    \n",
    "    for i, (x,y,w,h) in enumerate(bounding_boxes):\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), color, bounding_box_thickness)\n",
    "        \n",
    "        title = 'Index %d'%i\n",
    "        cv2.putText(image, title, (x + title_add_x, y + title_add_y), fontFace=font_face, fontScale=font_scale, color=color, thickness=font_thickness)\n",
    "    \n",
    "    return image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54450fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_bgr):\n",
    "    image_color = image_bgr.copy()\n",
    "    image_gray = cv2.cvtColor(image_color, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray = cv2.equalizeHist(image_gray)\n",
    "        \n",
    "    images = []\n",
    "    \n",
    "    bounding_boxes = face_cascade.detectMultiScale(image_gray)\n",
    "    for (x,y,w,h) in bounding_boxes:\n",
    "        image = image_gray[x:x+w, y:y+h]\n",
    "        images.append(image)\n",
    "    \n",
    "    images = [Preprocess.preprocess_gray(image) for image in images]\n",
    "    images = np.asarray(images, 'float32')\n",
    "    \n",
    "    results = []\n",
    "    if(len(images) > 0):\n",
    "        results = model(images).numpy()\n",
    "    \n",
    "    result_image = image_color.copy()\n",
    "    result_image = draw_bounding_boxes(result_image, bounding_boxes)\n",
    "    result_image = draw_results(result_image, results)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "def query_image(source, target):\n",
    "    image = cv2.imread(source)\n",
    "    result_image = predict_image(image)\n",
    "    cv2.imwrite(target, result_image)\n",
    "    \n",
    "def query_video(source, target):\n",
    "    print('Reading video from %s'%source, end='\\r')\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    assert(cap.isOpened())\n",
    "    frames = []\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    while(cap.isOpened()):\n",
    "        status, frame = cap.read()\n",
    "        if(status):\n",
    "            frame = predict_image(frame)\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    \n",
    "    height, width = frames[0].shape[:2]\n",
    "    \n",
    "    out = cv2.VideoWriter(target, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "    print('Successfully saved video to %s'%target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ce74a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved video to ../Resources/video/sample_result_video.mkv\n"
     ]
    }
   ],
   "source": [
    "query_video( os.path.join(dir_resources,'video/sample_video.mp4'),  os.path.join(dir_resources,'video/sample_result_video.mkv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
